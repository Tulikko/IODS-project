# 5: Dimensionality reduction techniques

**Part 1**

```{r}
# Libraries
library(dplyr); library(GGally);library(corrplot)

# Fetching the wrangled data
human <- read.table("data/human.txt")

glimpse(human)

ggpairs(human)

cor(human) %>% corrplot (type = "lower", tl.cex = 0.7, tl.pos="d", cl.pos="r")

ggplot(human, aes(x = Edu, y = Life)) + geom_point() + geom_smooth(method = "lm") + ggtitle("Education equals life?")

ggplot(human, aes(x = Maternal_mort, y = Life)) + geom_point() + geom_smooth(method = "lm") + ggtitle("Maternal mortality does not equal life.")

```

**Part 2**

First, we perform PCA (principal component analysis) to the unaltered data:

```{r, message=FALSE, warning=FALSE}

# PCA (with the SVD method)
pca_human1 <- prcomp(human)
summary(pca_human1)

# Biplot of the PC representation and the original variables
biplot(pca_human1, choices = 1:2, cex = c(0.5, 0.7), col = c("grey80", "deeppink2"))

```
\
The variable GNI completely dominates and explains all the variation in the raw data, as the numerical values of GNI are so huge in comparison to the other variables. Thus, we need to standardize the data to get more meaningful results from this analysis.


**Part 3**

```{r, message=FALSE, warning=FALSE}
# Scaling the data and performing the PCA analysis again
human_s <- scale(human)
pca_human <- prcomp(human_s)

summary(pca_human)

# Calculate and print rounded percentages of variance
s <- summary(pca_human)
pca_p <- round(1*s$importance[2, ]*100, digits = 1)
pca_p

# Assign corresponding percentages to labels
pc_l <- paste0(names(pca_p), " (", pca_p, " %)")

# Scaled biplot with corresponding variance percentages in labels
biplot(pca_human, choices = 1:2, cex = c(0.5, 0.7), col = c("grey80", "deeppink2"), xlab = pc_l[1], ylab = pc_l[2])

```
\
Now the data is much more readable. 

```{r}

```


**Part 4**

```{r}

```

**Part 5**

Here we explore data of tea drinking habits from FactoMineR library. The original dataset contains 36 different variables (see colnames below for the full list), but I decided to separate the data containing information about tea drinking places, the type of tea (earl grey, green or black) and age quartales (the variable age_G) for a closer look. We visualize these selected variables and their internal distribution by simple column charts, and then perform Multiple Correspondence Analysis (MCA) to see if any patterns can be interpreted. 

```{r, message=FALSE, warning=FALSE}
library(FactoMineR); library(tidyr)
data("tea")
colnames(tea)

teaplaces <- tea[,c(7:13,23)]

colnames(teaplaces)

gather(teaplaces) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))

mca <- MCA(teaplaces, graph = F)
summary(mca)

plot(mca, invisible=c("ind"), habillage = "quali")
```
The first dimension explains 15.06 % of the variance in this data subset, and adding Dim 2, the cumulative explanatory value ends up to 26.76 %. This is not very high explanatory value, but we can see some interesting patterns from the visualization nevertheless. Drinking green tea clusters to the far left and together with "not somewhere" values - home being the closest place variable to it. Earl Grey is most likely drank by young people, and not at home. Black tea is favored by the older folks. Out of this test group, the 35-44 year old age quartile is the most likely to drink tea in a tearoom or restaurant. They will also most likely drink black tea, but this preference is not as strong as within the oldest group. From the previous column charts we saw that the green tea drinkers, as well as those who drank tea somewhere else than "home", were in the clear minority, which explains why these groups are so distinguished in the MCA biplot.
